###datafile参数以demo.sh传参实现

[LogReg]
#model支持梯度下降和随机梯度下降gradAscent,stoGradAscent
model:gradAscent
#学习率
alpha:0.002
#迭代次数
iter:1000
datafile:logReg.txt

[LineReg]
#model支持线性回归，岭回归，局部加权线性回归
model:regression
#岭回归lamd
lamd:0.01
#局部加权线下回归参数k
k:100
datafile:lineReg.txt

[SoftMaxReg]
#model支持梯度下降和随机梯度下降gradAscent,stoGradAscent
model:gradAscent
alpha:0.003
iter:1000
datafile:logReg.txt

[DNN]
initialization:he
learn_rateing:0.1
iter:1000
lambd:0.1
keep_prob:0.5
print_cost:true
optimizer:gd
mini_batch_size:64
beta1:0.9
beta2:0.999
epsilon:0.00000001
datafile:logReg.txt

[SVM]
#惩罚因子
C:0.6
#软间隔
soft:0.001
#bias
b:0
#迭代次数
iter:100
datafile:logReg.txt

[Adaboost]
#弱分类器个数
numIt:10
datafile:adaboost.txt

[DTree]
#model支持ID3,C4.5,CART分类树
model:ID3
datafile:id3.txt

#CART回归树
[CART]
datafile:cart.txt

[RF]
#弱分类器数
numIt:50
#弱分类树的深度
deep:5
#最小分裂err
epsilon:0.01
datafile:rf.txt

[KMeans]
K:3
datafile:kmeans.txt

[KNN]
K:10
datafile:knn.txt

[Bayes]
datafile:bayes.txt

[GMM]
K:20
iter:10

[HMM]
datafile:Ntest.txt

[HMM_CWS]
datafile:pku_training.txt

[MEMM_CWS]
datafile:pku_training.txt

[CRF_CWS]
datafile:pku_training.txt
